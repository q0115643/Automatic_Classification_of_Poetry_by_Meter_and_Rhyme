{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are modeled with **a character-based RNN with LSTM**, which produces two vectors.\n",
    "\n",
    "The forward vector will have a representation of the character sequence from the left to the right.\n",
    "\n",
    "The backward one will have the same in the reversed order.\n",
    "\n",
    "Our insight is that this character-based LSTM captures the phonological structure of the word from its graphemes/characters.\n",
    "\n",
    "These two vectors are concatenated together with the whole **wordâ€™s embedding**\n",
    "(the embeddings could be pre-trained from larger corpora or trained jointly for the task).\n",
    "\n",
    "The vector of these three elements will represent each word in the sequence. Then, for each word, there will be a **word-level LSTM**, which will produce an output for each word, with its right and left context information.\n",
    "\n",
    "Finally, this output will go through a **CRF layer** to get the optimal output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image_ref/BiRNN_before_CRF.png\">\n",
    "\n",
    "BiRNN-CRF structure concating with pre-trainned word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Util functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_embedding(input_embedding):\n",
    "    \"\"\"\n",
    "    Initialize embedding\n",
    "    \"\"\"\n",
    "    bias = np.sqrt(3.0 / input_embedding.size(1))\n",
    "    nn.init.uniform_(input_embedding, -bias, bias)\n",
    "    # torch.nn.init.uniform_(tensor, a=0, b=1)\n",
    "    # fills the input Tensor with values drawn form the uniform distribution U(a, b)\n",
    "    \n",
    "def init_lstm(input_lstm):\n",
    "    \"\"\"\n",
    "    Initialize lstm\n",
    "    \"\"\"\n",
    "    for ind in range(0, input_lstm.num_layers):\n",
    "        weight = eval('input_lstm.weight_ih_l' + str(ind))\n",
    "        bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "        nn.init.uniform(weight, -bias, bias)\n",
    "        weight = eval('input_lstm.weight_hh_l' + str(ind))\n",
    "        bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "        nn.init.uniform(weight, -bias, bias)\n",
    "    if input_lstm.bidirectional:  # add reverse params\n",
    "        for ind in range(0, input_lstm.num_layers):\n",
    "            weight = eval('input_lstm.weight_ih_l' + str(ind) + '_reverse')\n",
    "            bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "            nn.init.uniform(weight, -bias, bias)\n",
    "            weight = eval('input_lstm.weight_hh_l' + str(ind) + '_reverse')\n",
    "            bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "            nn.init.uniform(weight, -bias, bias)\n",
    "\n",
    "    if input_lstm.bias:\n",
    "        for ind in range(0, input_lstm.num_layers):\n",
    "            weight = eval('input_lstm.bias_ih_l' + str(ind))\n",
    "            weight.data.zero_()\n",
    "            weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "            weight = eval('input_lstm.bias_hh_l' + str(ind))\n",
    "            weight.data.zero_()\n",
    "            weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "        if input_lstm.bidirectional:\n",
    "            for ind in range(0, input_lstm.num_layers):\n",
    "                weight = eval('input_lstm.bias_ih_l' + str(ind) + '_reverse')\n",
    "                weight.data.zero_()\n",
    "                weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "                weight = eval('input_lstm.bias_hh_l' + str(ind) + '_reverse')\n",
    "                weight.data.zero_()\n",
    "                weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the Model**\n",
    "\n",
    "- for character embedding, initialize lookup table\n",
    "- train them by BiRNN with LSTM or CNN\n",
    "\n",
    "- and concatenate character-level representation with pre-trained word-level representation\n",
    "- pre-word lookup-table <= initialize using word2vec like method.\n",
    "- UNK embedding if not in lookup-table\n",
    "- UNK embedding is trained with singletons with probability 0.5\n",
    "\n",
    "- add drop-out to after concanate\n",
    "\n",
    "- done building our embeddings\n",
    "\n",
    "- use new LSTM-CRF model to generate the target sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tage_to_ix, embedding_dim, hidden_dim, char_lstm_dim=25,\n",
    "                      char_to_ix=None, pre_word_embeds=None, char_embedding_dim=25, use_gpu=False,\n",
    "                      n_cap=None, cap_embedding_dim=None, use_crf=True, char_mode='CNN'):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.use_gpu = use_gpu\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.n_cap = n_cap\n",
    "        self.cap_embedding_dim = cap_embedding_dim\n",
    "        self.use_crf = use_crf\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.out_channels = char_lstm_dim  #  #of output channels\n",
    "        self.char_mode = char_mode\n",
    "        # char_mode: CNN or LSTM\n",
    "        # char_lstm_dim: #of output channels\n",
    "        # hidden_dim: #of hidden dimensions\n",
    "        print('char_mode: %s, out_channels: %d, hidden_dim: %d, ' % (char_mode, char_lstm_dim, hidden_dim))\n",
    "        \n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            self.cap_embeds = nn.Embedding(self.n_cap, self.cap_embedding_dim)\n",
    "            # torch.nn.Embedding(num_embeddings, embedding_dim, ...)\n",
    "            # lookup table that stores embeddings of a fixed dictionary and size\n",
    "            # num_embeddings: size of the dictionary of embeddings\n",
    "            # embedding_dim: the size of each embedding vector\n",
    "            init_embedding(self.cap_embeds.weight)  # embeddings for cap initialize\n",
    "        \n",
    "        if char_embedding_dim is not None:\n",
    "            self.char_lstm_dim = char_lstm_dim\n",
    "            self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
    "            init_embedding(self.char_embeds.weight)\n",
    "            # embeddings for chars initialize\n",
    "            if self.char_mode == 'LSTM':\n",
    "                self.char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                init_lstm(self.char_lstm)  # initialize LSTM\n",
    "            if self.char_mode == 'CNN':\n",
    "                self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2, 0))\n",
    "        \n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pre_word_embeds is not None:\n",
    "            self.pre_word_embeds = True\n",
    "            self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
    "            # torch.nn.Parmeter(data)\n",
    "            # Tensor that is to be considered a module parameter\n",
    "            # data: parameter tensor\n",
    "            # requires_grad(bool, optional): Default: True\n",
    "        else:\n",
    "            self.pre_word_embeds = False\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5) # Dropout layer\n",
    "        # torch.nn.Dropout(p=0.5, inplace=False)\n",
    "        # p: probability of an element to be zeroed\n",
    "        # inplace: if set to True, will do this operation in-place. Default: False\n",
    "        \n",
    "        # until here was making the embedding for words (character embedding + pre-word embedding)\n",
    "        ######################################################\n",
    "        # from here is the BiRNN-CRF model using the embeddings above\n",
    "        \n",
    "        if self.n_cap and self.cap_embedding_dim:\n",
    "            if self.char_mode == 'LSTM':\n",
    "                self.lstm = nn.LSTM(embedding_dim+char_lstm_dim*2+cap_embedding_dim, hidden_dim, bidirectional=True)\n",
    "            if self.char_mode == 'CNN':\n",
    "                self.lstm = nn.LSTM(embedding_dim+self.out_channels+cap_embedding_dim, hidden_dim, bidirectional=True)\n",
    "        else:\n",
    "            if self.char_mode == 'LSTM':\n",
    "                self.lstm = nn.LSTM(embedding_dim+char_lstm_dim*2, hidden_dim, bidirectional=True)\n",
    "            if self.char_mode == 'CNN':\n",
    "                self.lstm = nn.LSTM(embedding_dim+self.out_channels, hidden_dim, bidirectional=True)\n",
    "        init_lstm(self.lstm)\n",
    "        self.hw_trans = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.hw_gate = nn.Linear(self.out_channels, self.out_channels)\n",
    "        self.h2_h1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
    "        init_linear(self.h2_h1)\n",
    "        init_linear(self.hidden2tag)\n",
    "        init_linear(self.hw_gate)\n",
    "        init_linear(self.hw_trans)\n",
    "        \n",
    "        if self.use_crf:\n",
    "            sef.transitions = nn.Parameter(\n",
    "                torch.zeros(self.tagset_size, self.target_size))\n",
    "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
